{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayteaftw/NLP-quora-duplicate-detection/blob/main/quora_duplicate_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9B9RfXUgKJV"
      },
      "source": [
        "We are only using test.csv(400k training examples). We are gonna do train, cv, test split on it. Lets just do a simple logistic regression on this and set a baseline performance for our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X-Mog1K-ej0T"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "omhBufyrSTDt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import OrderedDict\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUYmQGxEi8XM",
        "outputId": "ad4af9d7-0797-467a-bfb3-9ef9def8e91a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive/')\n",
        "path = '/content/gdrive/MyDrive/NLP_Final_Project/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW2U2MJAY_MW"
      },
      "source": [
        "# Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PnqG78znbHWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6748bc59-78d8-4aa6-fcb9-bc49a12993cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(404290,)\n",
            "(404290, 5)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(path+'train.csv')\n",
        "y = np.array(df['is_duplicate'])\n",
        "X = df[['id', 'qid1', 'qid2', 'question1', 'question2']]\n",
        "X = np.array(X)\n",
        "print(y.shape)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KYYTtlNqbJka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db95d21c-7ae6-4629-8caa-00a812687af7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['What is the step by step guide to invest in share market in india?',\n",
              "       'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
              "       'How can I increase the speed of my internet connection while using a VPN?',\n",
              "       ..., 'What is one coin?',\n",
              "       'What is the approx annual cost of living while studying in UIC Chicago, for an Indian student?',\n",
              "       'What is like to have sex with cousin?'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X_train = df[['question1','question2' ]]\n",
        "X_train = np.array(X_train)\n",
        "X_train[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-pVsecKfZB-1"
      },
      "outputs": [],
      "source": [
        "def train(train_dataset, test_dataset,feature_size):\n",
        "    train_len = len(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset,batch_size=64)\n",
        "    \n",
        "    if test_dataset != None:\n",
        "        test_len = len(test_dataset)\n",
        "        test_dataloader = DataLoader(test_dataset,batch_size=64)\n",
        "\n",
        "    model = LogisticModel(feature_size)\n",
        "    model.to(device)\n",
        "    loss_fn = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2,betas=(0.9, 0.999))\n",
        "\n",
        "\n",
        "    epochs = 500\n",
        "    epoch_history = []\n",
        "    fold_train_loss_history, fold_val_loss_history = [], []\n",
        "    fold_val_acc_history = []\n",
        "    \n",
        "    for e in range(1,epochs+1):\n",
        "        \n",
        "        total_train_loss = 0\n",
        "        total_train_correct = 0\n",
        "        for batch_x, batch_y in train_dataloader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "    \n",
        "            # Compute prediction error\n",
        "            pred = torch.squeeze(model(batch_x))\n",
        "            loss = loss_fn(pred, batch_y)\n",
        "            \n",
        "            \n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            #Save Training Loss and total correct\n",
        "            total_train_loss += loss.item()\n",
        "            out = (pred>0.5).float()\n",
        "            total_train_correct += sum(out==batch_y).float().sum()\n",
        "     \n",
        "        if e == 1 or e % 10 == 0:\n",
        "            with torch.no_grad():\n",
        "                epoch_history.append(e)\n",
        "\n",
        "                train_acc = total_train_correct / train_len\n",
        "                avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "                fold_train_loss_history.append(avg_train_loss)\n",
        "                if test_dataset != None:\n",
        "                    total_val_correct = 0\n",
        "                    total_val_loss = 0\n",
        "                    for val_x, val_y in test_dataloader:\n",
        "                        val_x, val_y = val_x.to(device), val_y.to(device)\n",
        "                        val_pred = torch.squeeze(model(val_x))\n",
        "                        val_out = (val_pred>0.5).float()\n",
        "                        val_loss = loss_fn(val_pred, val_y)\n",
        "                        total_val_loss += val_loss.cpu()\n",
        "                        total_val_correct += sum(val_out==val_y).float().sum()\n",
        "\n",
        "                    val_acc = total_val_correct / test_len\n",
        "                    avg_val_loss = total_val_loss / len(test_dataloader)\n",
        "                    fold_val_acc_history.append(val_acc.cpu())\n",
        "                    fold_val_loss_history.append(avg_val_loss)\n",
        "               \n",
        "\n",
        "                    print(f\"epoch: {e}, Train loss: {avg_train_loss:>4f},  Train Acc: {train_acc:>4f}, Val Loss: {avg_val_loss::>4f}, Val Acc: {val_acc:>4f}\")\n",
        "                else:\n",
        "                    print(f\"epoch: {e}, Train loss: {avg_train_loss:>4f},  Train Acc: {train_acc:>4f}\")   \n",
        "    return fold_train_loss_history, fold_val_loss_history, fold_val_acc_history, epoch_history,model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdugqPIi9iGm"
      },
      "source": [
        "# Glove50 Logsitic Regregression Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiOtdSh1UrYi"
      },
      "outputs": [],
      "source": [
        "class CustomDataset():\n",
        "    def __init__(self,X,y )-> None:\n",
        "        \n",
        "\n",
        "        word_embeddings = pd.read_csv(path+'glove.6B.50d.txt.zip',\n",
        "                               header=None, sep=' ', index_col=0,\n",
        "                               nrows=100000, compression='zip', encoding='utf-8', quoting=3)\n",
        "        # Build a dict that will map from string word to 50-dim vector\n",
        "        word_list = word_embeddings.index.values.tolist()\n",
        "        word2vec = OrderedDict(zip(word_list, word_embeddings.values))\n",
        "        \n",
        "\n",
        "        q1 = []\n",
        "        q2 = []\n",
        "        a = []\n",
        "        for (x1, x2),y1 in zip(X,y):\n",
        "          if isinstance(x1, str) and isinstance(x2, str):\n",
        "            q1.append(x1)\n",
        "            q2.append(x2)\n",
        "            a.append(y1)\n",
        "          else:\n",
        "            print(x1,x2)\n",
        "\n",
        "        pair_len = len(q1)\n",
        "\n",
        "        x_embed_q1 = np.zeros((pair_len, 50))\n",
        "        x_embed_q2 = np.zeros((pair_len, 50))        \n",
        "        for idx, (x1, x2) in enumerate(zip(q1,q2)):\n",
        "\n",
        "          question1 = x1.strip().split(\" \")\n",
        "          question2 = x2.strip().split(\" \")\n",
        "\n",
        "          for word in question1:\n",
        "            if word in word2vec:\n",
        "              x_embed_q1[idx] += word2vec[word]\n",
        "            x_embed_q1[idx] /= len(question1)\n",
        "\n",
        "          for word in question2:\n",
        "            if word in word2vec:\n",
        "              x_embed_q2[idx] += word2vec[word]\n",
        "            x_embed_q2[idx] /= len(question2)\n",
        "        \n",
        "\n",
        "        x_embed = np.concatenate((x_embed_q1,x_embed_q2),axis=1)\n",
        "        print(x_embed.shape)\n",
        "\n",
        "        self.feature_size = x_embed.shape[1]\n",
        "        self.x_train = torch.Tensor(x_embed)[:100000]\n",
        "        self.y_train = torch.Tensor(a)[:100000]\n",
        "        print(self.feature_size, self.x_train.shape, self.y_train.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x_train.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x_train[idx], self.y_train[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VqDBOcWSNev"
      },
      "outputs": [],
      "source": [
        "class LogisticModel(nn.Module):\n",
        "    def __init__(self,input_size):\n",
        "        super(LogisticModel,self).__init__()\n",
        "        self.w = nn.Linear(input_size,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.sigmoid(self.w(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPiSkOTNY0rh",
        "outputId": "698be8f1-3af7-4111-9465-1f906343ac94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How can I develop android app? nan\n",
            "How can I create an Android app? nan\n",
            "nan My Chinese name is Haichao Yu. What English name is most suitable for me considering the pronounciation of my Chinese name?\n",
            "(404287, 100)\n",
            "100 torch.Size([100000, 100]) torch.Size([100000])\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "dataset = CustomDataset(X_train,y)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXKsbDErgQAK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ruINwqrgU00"
      },
      "outputs": [],
      "source": [
        "#For Testing\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "kfold.split(dataset)\n",
        "train_loss_history, val_loss_history = [], []\n",
        "val_acc_history = []\n",
        "for fold, (train_idxs, test_idxs) in enumerate(kfold.split(dataset)):\n",
        "\n",
        "    print(f'Starting fold {fold}')\n",
        "    train_dataset = torch.utils.data.Subset(dataset,train_idxs)\n",
        "    test_dataset = torch.utils.data.Subset(dataset,test_idxs)\n",
        "    \n",
        "    fold_train_loss_history, fold_val_loss_history, fold_val_acc_history, epoch_history, _ = train(train_dataset=train_dataset,test_dataset=test_dataset,feature_size=dataset.feature_size)\n",
        "\n",
        "    train_loss_history.append(fold_train_loss_history)\n",
        "    val_loss_history.append(fold_val_loss_history)\n",
        "    val_acc_history.append(fold_val_acc_history) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITY2hjQKTDM4"
      },
      "source": [
        "# Sentence Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Evn_hzLWDRoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0fe80c6-f9b8-4fc1-cb25-dd5d942da17a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.29.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting p_tqdm\n",
            "  Downloading p_tqdm-1.4.0.tar.gz (5.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.45.0 in /usr/local/lib/python3.10/dist-packages (from p_tqdm) (4.65.0)\n",
            "Collecting pathos>=0.2.5 (from p_tqdm)\n",
            "  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from p_tqdm) (1.16.0)\n",
            "Collecting ppft>=1.7.6.6 (from pathos>=0.2.5->p_tqdm)\n",
            "  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill>=0.3.6 (from pathos>=0.2.5->p_tqdm)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pox>=0.3.2 (from pathos>=0.2.5->p_tqdm)\n",
            "  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\n",
            "Collecting multiprocess>=0.70.14 (from pathos>=0.2.5->p_tqdm)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: p_tqdm\n",
            "  Building wheel for p_tqdm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for p_tqdm: filename=p_tqdm-1.4.0-py3-none-any.whl size=5383 sha256=0bf6d8789db916d83aca7722962d54fe25e07b099098f2580a4ca13ae7d1cce5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/f1/4b/e9e4adb8e573e9c41176bc7a08c47bba6babedc75900f5d05e\n",
            "Successfully built p_tqdm\n",
            "Installing collected packages: ppft, pox, dill, multiprocess, pathos, p_tqdm\n",
            "Successfully installed dill-0.3.6 multiprocess-0.70.14 p_tqdm-1.4.0 pathos-0.3.0 pox-0.3.2 ppft-1.7.6.6\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install -U p_tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_EjEhMElDiDf"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from p_tqdm import p_map, p_umap, p_imap, p_uimap\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool"
      ],
      "metadata": {
        "id": "R6nTVeh3kHKM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "r9rbCmavDOAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea4a4b39-5d1f-41a4-9b86-2b1ecd9cb015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class SentenceTransformerDataset():\n",
        "    def __init__(self,X,y, pair_len=0)-> None:\n",
        "        \n",
        "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        \n",
        "        q1 = []\n",
        "        q2 = []\n",
        "        a = []\n",
        "        for (x1, x2),y1 in zip(X,y):\n",
        "          if isinstance(x1, str) and isinstance(x2, str):\n",
        "            q1.append(x1)\n",
        "            q2.append(x2)\n",
        "            a.append(y1)\n",
        "          else:\n",
        "            print(x1,x2)\n",
        "\n",
        "        pair_len = pair_len if pair_len else len(q1)\n",
        "\n",
        "        q1, q2, a = q1[:pair_len], q2[:pair_len], a[:pair_len]\n",
        "        x_embed_q1 = np.zeros((pair_len, 384))[:pair_len]\n",
        "        x_embed_q2 = np.zeros((pair_len, 384)) [:pair_len]\n",
        "\n",
        "        def compute(idx):\n",
        "           pass\n",
        "           #model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "           #x_embed_q1[idx] = model.encode(q1[idx])\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "        #mapping = [range(pair_len), [model]*pair_len]\n",
        "        items = [['a']*10 for _ in range(20)]\n",
        "        results = p_map(model.encode, q1)\n",
        "            \n",
        "                  \n",
        "      \n",
        "\n",
        "\n",
        "        x_embed = np.concatenate((x_embed_q1,x_embed_q2),axis=1)\n",
        "        \n",
        "        print(x_embed.shape)\n",
        "\n",
        "        self.feature_size = x_embed.shape[1]\n",
        "        self.setences = [q1,q2]\n",
        "        self.x_train = torch.Tensor(x_embed)\n",
        "        self.y_train = torch.Tensor(a)\n",
        "        print(self.feature_size, self.x_train.shape, self.y_train.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x_train.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x_train[idx], self.y_train[idx]\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "class SentenceTransformerDataset():\n",
        "    def __init__(self,X,y, pair_len=0)-> None:\n",
        "        \n",
        "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        \n",
        "        q1 = []\n",
        "        q2 = []\n",
        "        a = []\n",
        "        for (x1, x2),y1 in zip(X,y):\n",
        "          if isinstance(x1, str) and isinstance(x2, str):\n",
        "            q1.append(x1)\n",
        "            q2.append(x2)\n",
        "            a.append(y1)\n",
        "          else:\n",
        "            print(x1,x2)\n",
        "\n",
        "        pair_len = pair_len if pair_len else len(q1)\n",
        "\n",
        "        q1, q2, a = q1[:pair_len], q2[:pair_len], a[:pair_len]\n",
        "        x_embed_q1 = np.zeros((pair_len, 384))[:pair_len]\n",
        "        x_embed_q2 = np.zeros((pair_len, 384)) [:pair_len]       \n",
        "        for idx, (x1, x2) in tqdm(enumerate(zip(q1,q2)), total=pair_len):\n",
        "          \n",
        "          \n",
        "          x_embed_q1[idx] = model.encode(x1)\n",
        "          x_embed_q2[idx] = model.encode(x2)\n",
        "\n",
        "\n",
        "          x_embed = np.concatenate((x_embed_q1,x_embed_q2),axis=1)\n",
        "        \n",
        "        print(x_embed.shape)\n",
        "\n",
        "        self.feature_size = x_embed.shape[1]\n",
        "        self.setences = [q1,q2]\n",
        "        self.x_train = torch.Tensor(x_embed)\n",
        "        self.y_train = torch.Tensor(a)\n",
        "        print(self.feature_size, self.x_train.shape, self.y_train.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x_train.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x_train[idx], self.y_train[idx]\n",
        "\"\"\"\n",
        "print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4841e786a60a4a9fa0152d84c86b0cbe",
            "e86357e782ea4a2e8e6be564b50b1af7",
            "3a2b16d73e8a408ca375b6d66b8da06c",
            "48ebc103db15413497c33dcea556ce59",
            "582c6fa7dfd24856b5e891cf910bf83b",
            "71966cbb88fe4d839b5b552d1a57a2e4",
            "47815950a5654644a1b739d36934735e",
            "a5e8ed176a0247449c7d8c2df33ed02e",
            "34130f0f9d57411aabef6aefc620e31b",
            "b366bfd72c764a28b395121ad7117e53",
            "138c2a73eed74ba6ab13f9d9c7ae33f4"
          ]
        },
        "id": "m3Kqx5xWXThD",
        "outputId": "b9774a21-b821-46e6-e773-25f1e40507f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How can I develop android app? nan\n",
            "How can I create an Android app? nan\n",
            "nan My Chinese name is Haichao Yu. What English name is most suitable for me considering the pronounciation of my Chinese name?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/404287 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4841e786a60a4a9fa0152d84c86b0cbe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process ForkPoolWorker-9:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/queues.py\", line 370, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dill/_dill.py\", line 286, in loads\n",
            "    return load(file, ignore, **kwds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dill/_dill.py\", line 272, in load\n",
            "    return Unpickler(file, ignore=ignore, **kwds).load()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dill/_dill.py\", line 419, in load\n",
            "    obj = StockUnpickler.load(self)\n",
            "_pickle.UnpicklingError: invalid load key, '\\xbc'.\n",
            "Process ForkPoolWorker-10:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/queues.py\", line 370, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dill/_dill.py\", line 286, in loads\n",
            "    return load(file, ignore, **kwds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dill/_dill.py\", line 272, in load\n",
            "    return Unpickler(file, ignore=ignore, **kwds).load()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dill/_dill.py\", line 419, in load\n",
            "    obj = StockUnpickler.load(self)\n",
            "_pickle.UnpicklingError: invalid load key, '\\xbb'.\n",
            "Process ForkPoolWorker-13:\n",
            "Process ForkPoolWorker-14:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/queues.py\", line 367, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/synchronize.py\", line 101, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/pool.py\", line 114, in worker\n",
            "    task = get()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/queues.py\", line 368, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/connection.py\", line 224, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/connection.py\", line 429, in _recv_bytes\n",
            "    return self._recv(size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/multiprocess/connection.py\", line 387, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-0737bc896b99>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcreate_bert_encoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mbert_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformerDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpair_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;31m# Save the object to a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Writing Dataset to Drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-7a072b6204bc>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, y, pair_len)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#mapping = [range(pair_len), [model]*pair_len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"num_cpus\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/p_tqdm/p_tqdm.py\u001b[0m in \u001b[0;36mp_map\u001b[0;34m(function, *iterables, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mordered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mordered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/p_tqdm/p_tqdm.py\u001b[0m in \u001b[0;36m_parallel\u001b[0;34m(ordered, function, *iterables, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mtqdm_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tqdm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "create_bert_encoding = True\n",
        "file_name = 'bert_encoding_max.pkl'\n",
        "\n",
        "if create_bert_encoding:\n",
        "  bert_dataset = SentenceTransformerDataset(X_train,y,pair_len=0)\n",
        "  # Save the object to a file\n",
        "  print(f'Writing Dataset to Drive')\n",
        "  with open(path+file_name, 'wb') as f:\n",
        "      pickle.dump(bert_dataset, f)\n",
        "  print(f'Dataset Written!')\n",
        "\n",
        "else:\n",
        "  # Load the object from the file\n",
        "\n",
        "  if not os.path.isfile(path+file_name):\n",
        "    raise ValueError(\"No Dataset in drive\")\n",
        "  else:\n",
        "    print(f'Loading Dataset from Drive')\n",
        "    with open(path+file_name, 'rb') as f:\n",
        "        bert_dataset = pickle.load(f)\n",
        "    print(f'Dataset Load!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJBS83PJeFmG"
      },
      "outputs": [],
      "source": [
        "#For Testing\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "kfold.split(dataset)\n",
        "train_loss_history, val_loss_history = [], []\n",
        "val_acc_history = []\n",
        "for fold, (train_idxs, test_idxs) in enumerate(kfold.split(dataset)):\n",
        "\n",
        "    print(f'Starting fold {fold}')\n",
        "    train_dataset = torch.utils.data.Subset(dataset,train_idxs)\n",
        "    test_dataset = torch.utils.data.Subset(dataset,test_idxs)\n",
        "    \n",
        "    fold_train_loss_history, fold_val_loss_history, fold_val_acc_history, epoch_history, _ = train(train_dataset=train_dataset,test_dataset=test_dataset,feature_size=dataset.feature_size)\n",
        "\n",
        "    train_loss_history.append(fold_train_loss_history)\n",
        "    val_loss_history.append(fold_val_loss_history)\n",
        "    val_acc_history.append(fold_val_acc_history) "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PdugqPIi9iGm"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4841e786a60a4a9fa0152d84c86b0cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e86357e782ea4a2e8e6be564b50b1af7",
              "IPY_MODEL_3a2b16d73e8a408ca375b6d66b8da06c",
              "IPY_MODEL_48ebc103db15413497c33dcea556ce59"
            ],
            "layout": "IPY_MODEL_582c6fa7dfd24856b5e891cf910bf83b"
          }
        },
        "e86357e782ea4a2e8e6be564b50b1af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71966cbb88fe4d839b5b552d1a57a2e4",
            "placeholder": "​",
            "style": "IPY_MODEL_47815950a5654644a1b739d36934735e",
            "value": "  0%"
          }
        },
        "3a2b16d73e8a408ca375b6d66b8da06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5e8ed176a0247449c7d8c2df33ed02e",
            "max": 404287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34130f0f9d57411aabef6aefc620e31b",
            "value": 0
          }
        },
        "48ebc103db15413497c33dcea556ce59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b366bfd72c764a28b395121ad7117e53",
            "placeholder": "​",
            "style": "IPY_MODEL_138c2a73eed74ba6ab13f9d9c7ae33f4",
            "value": " 0/404287 [00:18&lt;?, ?it/s]"
          }
        },
        "582c6fa7dfd24856b5e891cf910bf83b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71966cbb88fe4d839b5b552d1a57a2e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47815950a5654644a1b739d36934735e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5e8ed176a0247449c7d8c2df33ed02e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34130f0f9d57411aabef6aefc620e31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b366bfd72c764a28b395121ad7117e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "138c2a73eed74ba6ab13f9d9c7ae33f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}