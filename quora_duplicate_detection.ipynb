{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayteaftw/NLP-quora-duplicate-detection/blob/main/quora_duplicate_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9B9RfXUgKJV"
      },
      "source": [
        "We are only using test.csv(400k training examples). We are gonna do train, cv, test split on it. Lets just do a simple logistic regression on this and set a baseline performance for our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5uMyRMhNdLT",
        "outputId": "427b0d8e-9726-439e-9a8f-5603b585f60e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n",
            "Path is /content/gdrive/MyDrive/NLP_Final_Project/\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive/')\n",
        "    path = '/content/gdrive/MyDrive/NLP_Final_Project/' \n",
        "except:\n",
        "    path = ''\n",
        "\n",
        "print(f\"Path is {path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "omhBufyrSTDt"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import OrderedDict\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUYmQGxEi8XM",
        "outputId": "b15bd072-9086-4e47-9971-dfe79b672297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW2U2MJAY_MW"
      },
      "source": [
        "# Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnqG78znbHWJ",
        "outputId": "d211540e-6d28-4e85-8e81-688d72658f1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(404290,)\n",
            "(404290, 5)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(path+'train.csv')\n",
        "y = np.array(df['is_duplicate'])\n",
        "X = df[['id', 'qid1', 'qid2', 'question1', 'question2']]\n",
        "X = np.array(X)\n",
        "print(y.shape)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYYTtlNqbJka",
        "outputId": "9b22bbe2-672d-4ec5-d22a-f33346467e8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['What is the step by step guide to invest in share market in india?',\n",
              "       'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
              "       'How can I increase the speed of my internet connection while using a VPN?',\n",
              "       ..., 'What is one coin?',\n",
              "       'What is the approx annual cost of living while studying in UIC Chicago, for an Indian student?',\n",
              "       'What is like to have sex with cousin?'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X_train = df[['question1','question2' ]]\n",
        "X_train = np.array(X_train)\n",
        "X_train[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-pVsecKfZB-1"
      },
      "outputs": [],
      "source": [
        "def train(train_dataset, test_dataset,feature_size):\n",
        "    train_len = len(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset,batch_size=64)\n",
        "    \n",
        "    if test_dataset != None:\n",
        "        test_len = len(test_dataset)\n",
        "        test_dataloader = DataLoader(test_dataset,batch_size=64)\n",
        "\n",
        "    model = LogisticModel(feature_size)\n",
        "    model.to(device)\n",
        "    loss_fn = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2,betas=(0.9, 0.999))\n",
        "\n",
        "\n",
        "    epochs = 500\n",
        "    epoch_history = []\n",
        "    fold_train_loss_history, fold_val_loss_history = [], []\n",
        "    fold_val_acc_history = []\n",
        "    \n",
        "    for e in range(1,epochs+1):\n",
        "        \n",
        "        total_train_loss = 0\n",
        "        total_train_correct = 0\n",
        "        for batch_x, batch_y in train_dataloader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "    \n",
        "            # Compute prediction error\n",
        "            pred = torch.squeeze(model(batch_x))\n",
        "            loss = loss_fn(pred, batch_y)\n",
        "            \n",
        "            \n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            #Save Training Loss and total correct\n",
        "            total_train_loss += loss.item()\n",
        "            out = (pred>0.5).float()\n",
        "            total_train_correct += sum(out==batch_y).float().sum()\n",
        "     \n",
        "        if e == 1 or e % 10 == 0:\n",
        "            with torch.no_grad():\n",
        "                epoch_history.append(e)\n",
        "\n",
        "                train_acc = total_train_correct / train_len\n",
        "                avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "                fold_train_loss_history.append(avg_train_loss)\n",
        "                if test_dataset != None:\n",
        "                    total_val_correct = 0\n",
        "                    total_val_loss = 0\n",
        "                    for val_x, val_y in test_dataloader:\n",
        "                        val_x, val_y = val_x.to(device), val_y.to(device)\n",
        "                        val_pred = torch.squeeze(model(val_x))\n",
        "                        val_out = (val_pred>0.5).float()\n",
        "                        val_loss = loss_fn(val_pred, val_y)\n",
        "                        total_val_loss += val_loss.cpu()\n",
        "                        total_val_correct += sum(val_out==val_y).float().sum()\n",
        "\n",
        "                    val_acc = total_val_correct / test_len\n",
        "                    avg_val_loss = total_val_loss / len(test_dataloader)\n",
        "                    fold_val_acc_history.append(val_acc.cpu())\n",
        "                    fold_val_loss_history.append(avg_val_loss)\n",
        "               \n",
        "\n",
        "                    print(f\"epoch: {e}, Train loss: {avg_train_loss:>4f},  Train Acc: {train_acc:>4f}, Val Loss: {avg_val_loss::>4f}, Val Acc: {val_acc:>4f}\")\n",
        "                else:\n",
        "                    print(f\"epoch: {e}, Train loss: {avg_train_loss:>4f},  Train Acc: {train_acc:>4f}\")   \n",
        "    return fold_train_loss_history, fold_val_loss_history, fold_val_acc_history, epoch_history,model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdugqPIi9iGm"
      },
      "source": [
        "# Glove50 Logsitic Regregression Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiOtdSh1UrYi"
      },
      "outputs": [],
      "source": [
        "class Glove50Dataset():\n",
        "    def __init__(self,X,y )-> None:\n",
        "        \n",
        "\n",
        "        word_embeddings = pd.read_csv(path+'glove.6B.50d.txt.zip',\n",
        "                               header=None, sep=' ', index_col=0,\n",
        "                               nrows=100000, compression='zip', encoding='utf-8', quoting=3)\n",
        "        # Build a dict that will map from string word to 50-dim vector\n",
        "        word_list = word_embeddings.index.values.tolist()\n",
        "        word2vec = OrderedDict(zip(word_list, word_embeddings.values))\n",
        "        \n",
        "\n",
        "        q1 = []\n",
        "        q2 = []\n",
        "        a = []\n",
        "        for (x1, x2),y1 in zip(X,y):\n",
        "          if isinstance(x1, str) and isinstance(x2, str):\n",
        "            q1.append(x1)\n",
        "            q2.append(x2)\n",
        "            a.append(y1)\n",
        "          else:\n",
        "            print(x1,x2)\n",
        "\n",
        "        pair_len = len(q1)\n",
        "\n",
        "        x_embed_q1 = np.zeros((pair_len, 50))\n",
        "        x_embed_q2 = np.zeros((pair_len, 50))        \n",
        "        for idx, (x1, x2) in enumerate(zip(q1,q2)):\n",
        "\n",
        "          question1 = x1.strip().split(\" \")\n",
        "          question2 = x2.strip().split(\" \")\n",
        "\n",
        "          for word in question1:\n",
        "            if word in word2vec:\n",
        "              x_embed_q1[idx] += word2vec[word]\n",
        "            x_embed_q1[idx] /= len(question1)\n",
        "\n",
        "          for word in question2:\n",
        "            if word in word2vec:\n",
        "              x_embed_q2[idx] += word2vec[word]\n",
        "            x_embed_q2[idx] /= len(question2)\n",
        "        \n",
        "\n",
        "        x_embed = np.concatenate((x_embed_q1,x_embed_q2),axis=1)\n",
        "        print(x_embed.shape)\n",
        "\n",
        "        self.feature_size = x_embed.shape[1]\n",
        "        self.x_train = torch.Tensor(x_embed)[:100000]\n",
        "        self.y_train = torch.Tensor(a)[:100000]\n",
        "        print(self.feature_size, self.x_train.shape, self.y_train.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x_train.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x_train[idx], self.y_train[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5VqDBOcWSNev"
      },
      "outputs": [],
      "source": [
        "class LogisticModel(nn.Module):\n",
        "    def __init__(self,input_size):\n",
        "        super(LogisticModel,self).__init__()\n",
        "        self.w = nn.Linear(input_size,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.sigmoid(self.w(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPiSkOTNY0rh",
        "outputId": "698be8f1-3af7-4111-9465-1f906343ac94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How can I develop android app? nan\n",
            "How can I create an Android app? nan\n",
            "nan My Chinese name is Haichao Yu. What English name is most suitable for me considering the pronounciation of my Chinese name?\n",
            "(404287, 100)\n",
            "100 torch.Size([100000, 100]) torch.Size([100000])\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "dataset = Glove50Dataset(X_train,y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ruINwqrgU00"
      },
      "outputs": [],
      "source": [
        "#For Testing\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "kfold.split(dataset)\n",
        "train_loss_history, val_loss_history = [], []\n",
        "val_acc_history = []\n",
        "for fold, (train_idxs, test_idxs) in enumerate(kfold.split(dataset)):\n",
        "\n",
        "    print(f'Starting fold {fold}')\n",
        "    train_dataset = torch.utils.data.Subset(dataset,train_idxs)\n",
        "    test_dataset = torch.utils.data.Subset(dataset,test_idxs)\n",
        "    \n",
        "    fold_train_loss_history, fold_val_loss_history, fold_val_acc_history, epoch_history, _ = train(train_dataset=train_dataset,test_dataset=test_dataset,feature_size=dataset.feature_size)\n",
        "\n",
        "    train_loss_history.append(fold_train_loss_history)\n",
        "    val_loss_history.append(fold_val_loss_history)\n",
        "    val_acc_history.append(fold_val_acc_history) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITY2hjQKTDM4"
      },
      "source": [
        "# Sentence Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evn_hzLWDRoh",
        "outputId": "2aa3c5ec-a73a-487c-be2a-3a9b06bbc462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=02af93bd740c06af98881f0af9dc5984832cd88a7a02eda0e635b14966a91315\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.14.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_EjEhMElDiDf"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9rbCmavDOAp",
        "outputId": "f9085c57-e1e6-40b5-9200-c490adf4bcd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "class SentenceTransformerDataset():\n",
        "    def __init__(self,X,y, pair_len=0)-> None:\n",
        "        \n",
        "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        \n",
        "        q1 = []\n",
        "        q2 = []\n",
        "        a = []\n",
        "        for (x1, x2),y1 in zip(X,y):\n",
        "          if isinstance(x1, str) and isinstance(x2, str):\n",
        "            q1.append(x1)\n",
        "            q2.append(x2)\n",
        "            a.append(y1)\n",
        "          else:\n",
        "            print(x1,x2)\n",
        "\n",
        "        pair_len = pair_len if pair_len else len(q1)\n",
        "\n",
        "        q1, q2, a = q1[:pair_len], q2[:pair_len], a[:pair_len]\n",
        "        x_embed_q1 = np.zeros((pair_len, 384))[:pair_len]\n",
        "        x_embed_q2 = np.zeros((pair_len, 384)) [:pair_len]\n",
        "\n",
        "        pool = model.start_multi_process_pool()\n",
        "\n",
        "\n",
        "        #Start the multi-process pool on all available CUDA devices\n",
        "        pool = model.start_multi_process_pool()\n",
        "\n",
        "        step_size = 10000\n",
        "        for start in tqdm(range(0, pair_len, step_size),total=pair_len//step_size):\n",
        "          stop = start + step_size if (start + step_size) < pair_len else (pair_len - 1)\n",
        "          x_embed_q1[start:stop] = model.encode_multi_process(q1[start:stop], pool)\n",
        "          x_embed_q2[start:stop] = model.encode_multi_process(q2[start:stop], pool)\n",
        "\n",
        "        #Optional: Stop the proccesses in the pool\n",
        "        model.stop_multi_process_pool(pool)\n",
        "\n",
        "        x_embed = np.concatenate((x_embed_q1,x_embed_q2),axis=1)\n",
        "        \n",
        "        print(x_embed.shape)\n",
        "\n",
        "        self.feature_size = x_embed.shape[1]\n",
        "        self.setences = [q1,q2]\n",
        "        self.x_train = torch.Tensor(x_embed)\n",
        "        self.y_train = torch.Tensor(a)\n",
        "        print(self.feature_size, self.x_train.shape, self.y_train.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x_train.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x_train[idx], self.y_train[idx]\n",
        "\n",
        "\n",
        "\n",
        "print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Kqx5xWXThD",
        "outputId": "99514ec1-eae4-4688-aaab-78f13977d728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'bert_encoding_max.pkl' exists in the drive! Would you like to replace? (y/n)n\n",
            "Loading Dataset from Drive\n",
            "Dataset Load!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "create_bert_encoding = True\n",
        "file_name = 'bert_encoding_max.pkl'\n",
        "\n",
        "\n",
        "run = 'y'\n",
        "if create_bert_encoding: \n",
        "  if os.path.isfile(path+file_name):\n",
        "    run = input(f\"'{file_name}' exists in the drive! Would you like to replace? (y/n)\")\n",
        "  if run == 'y':\n",
        "    bert_dataset = SentenceTransformerDataset(X_train,y,pair_len=0)\n",
        "    # Save the object to a file\n",
        "    print(f'Writing Dataset to Drive')\n",
        "    with open(path+file_name, 'wb') as f:\n",
        "        pickle.dump(bert_dataset, f)\n",
        "    print(f'Dataset Written!')\n",
        "\n",
        "if not create_bert_encoding or run != 'y':\n",
        "  # Load the object from the file\n",
        "  if not os.path.isfile(path+file_name):\n",
        "    raise ValueError(\"No Dataset in drive\")\n",
        "  else:\n",
        "    print(f'Loading Dataset from Drive')\n",
        "    with open(path+file_name, 'rb') as f:\n",
        "        bert_dataset = pickle.load(f)\n",
        "    print(f'Dataset Load!')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "train_percent = .8\n",
        "val_percent = 1 - train_percent\n",
        "sample_size = len(bert_dataset)\n",
        "train_size = int(sample_size * train_percent)\n",
        "val_size = sample_size - train_size\n",
        "\n",
        "\n",
        "print(f'Train|Val Percent: {train_percent}|{val_percent}')\n",
        "print(f'Train|Val Size: {train_size}|{val_size}')\n",
        "# Split the data into train and test sets\n",
        "train_dataset, test_dataset = random_split(bert_dataset, [train_size, val_size])\n"
      ],
      "metadata": {
        "id": "6unhCuBzzih3",
        "outputId": "fdae290b-474f-4902-ece7-0c9f17efd59e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train|Val Percent: 0.8|0.19999999999999996\n",
            "Train|Val Size: 323429|80858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import util\n",
        "\n",
        "feature_size = bert_dataset.feature_size//2\n",
        "total = 0\n",
        "for x, y in tqdm(test_dataset, total=len(test_dataset)):\n",
        "  q1 = x[:feature_size]\n",
        "  q2 = x[feature_size:]\n",
        "  cosine_scores = util.cos_sim(q1, q2).item()\n",
        "  total += 1 if (cosine_scores >= 0.5)==y else 0 \n",
        "\n",
        "\n",
        "percent = total / len(test_dataset)\n",
        "print(f\"Cosine Sim Acc: {percent}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "6d6b1d0345e3422bab91cd7efc3268e9",
            "6faaf5a8163a4888be475dd3a2ea7101",
            "92b095dd371a48d191029ac03ee1c880",
            "d63e381a50784339acc0626b417e2c04",
            "c8c14d12c93c43c9b4856bb52b8cdc7e",
            "500ec888adf4479c975a28c1704ea4aa",
            "dfe7fd9b56dc4df69cf6a0fef9b2c5af",
            "1fc9bb42854d4bd9887fa02bc2e8a955",
            "b7063d83b8d849eb9e62b94b6db4f3c8",
            "bbaa88de991647d28d2e09ef4034a28f",
            "eb7eac747f944729a9f92e2fb225273f"
          ]
        },
        "id": "5UW1ea5nkIe3",
        "outputId": "79cb7715-8c50-4ed9-8ae8-eb00d67265fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/80858 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d6b1d0345e3422bab91cd7efc3268e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Sim Acc: 0.5922357713522471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJBS83PJeFmG"
      },
      "outputs": [],
      "source": [
        "#For Testing\n",
        "fold_train_loss_history, fold_val_loss_history, fold_val_acc_history, epoch_history, _ = train(train_dataset=train_dataset,test_dataset=test_dataset,feature_size=bert_dataset.feature_size)\n",
        "\n",
        "train_loss_history.append(fold_train_loss_history)\n",
        "val_loss_history.append(fold_val_loss_history)\n",
        "val_acc_history.append(fold_val_acc_history) "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PdugqPIi9iGm"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d6b1d0345e3422bab91cd7efc3268e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6faaf5a8163a4888be475dd3a2ea7101",
              "IPY_MODEL_92b095dd371a48d191029ac03ee1c880",
              "IPY_MODEL_d63e381a50784339acc0626b417e2c04"
            ],
            "layout": "IPY_MODEL_c8c14d12c93c43c9b4856bb52b8cdc7e"
          }
        },
        "6faaf5a8163a4888be475dd3a2ea7101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_500ec888adf4479c975a28c1704ea4aa",
            "placeholder": "​",
            "style": "IPY_MODEL_dfe7fd9b56dc4df69cf6a0fef9b2c5af",
            "value": "100%"
          }
        },
        "92b095dd371a48d191029ac03ee1c880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fc9bb42854d4bd9887fa02bc2e8a955",
            "max": 80858,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7063d83b8d849eb9e62b94b6db4f3c8",
            "value": 80858
          }
        },
        "d63e381a50784339acc0626b417e2c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbaa88de991647d28d2e09ef4034a28f",
            "placeholder": "​",
            "style": "IPY_MODEL_eb7eac747f944729a9f92e2fb225273f",
            "value": " 80858/80858 [00:14&lt;00:00, 4751.82it/s]"
          }
        },
        "c8c14d12c93c43c9b4856bb52b8cdc7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "500ec888adf4479c975a28c1704ea4aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfe7fd9b56dc4df69cf6a0fef9b2c5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fc9bb42854d4bd9887fa02bc2e8a955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7063d83b8d849eb9e62b94b6db4f3c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbaa88de991647d28d2e09ef4034a28f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb7eac747f944729a9f92e2fb225273f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}