{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayteaftw/NLP-quora-duplicate-detection/blob/main/quora_duplicate_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9B9RfXUgKJV"
      },
      "source": [
        "We are only using test.csv(400k training examples). We are gonna do train, cv, test split on it. Lets just do a simple logistic regression on this and set a baseline performance for our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5uMyRMhNdLT",
        "outputId": "f6ee4134-cd5f-4b86-f98d-e24ca2ba9175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path is \n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive/')\n",
        "    path = '/content/gdrive/MyDrive/NLP_Final_Project/' \n",
        "except:\n",
        "    path = ''\n",
        "\n",
        "print(f\"Path is {path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "omhBufyrSTDt"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import OrderedDict\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUYmQGxEi8XM",
        "outputId": "5f4c9635-3e46-40b6-d058-99b456b0ae49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW2U2MJAY_MW"
      },
      "source": [
        "# Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnqG78znbHWJ",
        "outputId": "953e4dbe-307c-43e2-a8e0-90f451379770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(404290,)\n",
            "(404290, 5)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(path+'train.csv')\n",
        "y = np.array(df['is_duplicate'])\n",
        "X = df[['id', 'qid1', 'qid2', 'question1', 'question2']]\n",
        "X = np.array(X)\n",
        "print(y.shape)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYYTtlNqbJka",
        "outputId": "08d2a683-40ca-44c2-9d80-91c0bb25605c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['What is the step by step guide to invest in share market in india?',\n",
              "       'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
              "       'How can I increase the speed of my internet connection while using a VPN?',\n",
              "       ..., 'What is one coin?',\n",
              "       'What is the approx annual cost of living while studying in UIC Chicago, for an Indian student?',\n",
              "       'What is like to have sex with cousin?'], dtype=object)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train = df[['question1','question2' ]]\n",
        "X_train = np.array(X_train)\n",
        "X_train[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-pVsecKfZB-1"
      },
      "outputs": [],
      "source": [
        "def train(train_dataset, test_dataset,feature_size, model, params={}, print_step=10):\n",
        "    train_len = len(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset,batch_size=64)\n",
        "    \n",
        "    if test_dataset != None:\n",
        "        test_len = len(test_dataset)\n",
        "        test_dataloader = DataLoader(test_dataset,batch_size=64)\n",
        "\n",
        "    \n",
        "\n",
        "    loss_fn = params['loss']\n",
        "    epochs = params['epochs']\n",
        "    optimizer = params['optimizer']\n",
        "\n",
        "    \n",
        "\n",
        "    model.to(device)\n",
        "    epoch_history = []\n",
        "    fold_train_loss_history, fold_val_loss_history = [], []\n",
        "    fold_val_acc_history = []\n",
        "    \n",
        "    for e in range(1,epochs+1):\n",
        "        \n",
        "        total_train_loss = 0\n",
        "        total_train_correct = 0\n",
        "        for batch_x, batch_y in train_dataloader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "    \n",
        "            # Compute prediction error\n",
        "            pred = torch.squeeze(model(batch_x))\n",
        "            loss = loss_fn(pred, batch_y)\n",
        "            \n",
        "            \n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            #Save Training Loss and total correct\n",
        "            total_train_loss += loss.item()\n",
        "            out = (pred>0.5).float()\n",
        "            total_train_correct += sum(out==batch_y).float().sum()\n",
        "     \n",
        "        if e == 1 or e % print_step == 0:\n",
        "            with torch.no_grad():\n",
        "                epoch_history.append(e)\n",
        "\n",
        "                train_acc = total_train_correct / train_len\n",
        "                avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "                fold_train_loss_history.append(avg_train_loss)\n",
        "                if test_dataset != None:\n",
        "                    total_val_correct = 0\n",
        "                    total_val_loss = 0\n",
        "                    for val_x, val_y in test_dataloader:\n",
        "                        val_x, val_y = val_x.to(device), val_y.to(device)\n",
        "                        val_pred = torch.squeeze(model(val_x))\n",
        "                        val_out = (val_pred>0.5).float()\n",
        "                        val_loss = loss_fn(val_pred, val_y)\n",
        "                        total_val_loss += val_loss.cpu()\n",
        "                        total_val_correct += sum(val_out==val_y).float().sum()\n",
        "\n",
        "                    val_acc = total_val_correct / test_len\n",
        "                    avg_val_loss = total_val_loss / len(test_dataloader)\n",
        "                    fold_val_acc_history.append(val_acc.cpu())\n",
        "                    fold_val_loss_history.append(avg_val_loss)\n",
        "               \n",
        "\n",
        "                    print(f\"epoch: {e}, Train loss: {avg_train_loss:>4f},  Train Acc: {train_acc:>4f}, Val Loss: {avg_val_loss::>4f}, Val Acc: {val_acc:>4f}\")\n",
        "                else:\n",
        "                    print(f\"epoch: {e}, Train loss: {avg_train_loss:>4f},  Train Acc: {train_acc:>4f}\")   \n",
        "    return fold_train_loss_history, fold_val_loss_history, fold_val_acc_history, epoch_history,model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdugqPIi9iGm"
      },
      "source": [
        "# Glove50 Logsitic Regregression Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XiOtdSh1UrYi"
      },
      "outputs": [],
      "source": [
        "class Glove50Dataset():\n",
        "    def __init__(self,X,y )-> None:\n",
        "        \n",
        "\n",
        "        word_embeddings = pd.read_csv(path+'glove.6B.50d.txt.zip',\n",
        "                               header=None, sep=' ', index_col=0,\n",
        "                               nrows=100000, compression='zip', encoding='utf-8', quoting=3)\n",
        "        # Build a dict that will map from string word to 50-dim vector\n",
        "        word_list = word_embeddings.index.values.tolist()\n",
        "        word2vec = OrderedDict(zip(word_list, word_embeddings.values))\n",
        "        \n",
        "\n",
        "        q1 = []\n",
        "        q2 = []\n",
        "        a = []\n",
        "        for (x1, x2),y1 in zip(X,y):\n",
        "          if isinstance(x1, str) and isinstance(x2, str):\n",
        "            q1.append(x1)\n",
        "            q2.append(x2)\n",
        "            a.append(y1)\n",
        "          else:\n",
        "            print(x1,x2)\n",
        "\n",
        "        pair_len = len(q1)\n",
        "\n",
        "        x_embed_q1 = np.zeros((pair_len, 50))\n",
        "        x_embed_q2 = np.zeros((pair_len, 50))        \n",
        "        for idx, (x1, x2) in enumerate(zip(q1,q2)):\n",
        "\n",
        "          question1 = x1.strip().split(\" \")\n",
        "          question2 = x2.strip().split(\" \")\n",
        "\n",
        "          for word in question1:\n",
        "            if word in word2vec:\n",
        "              x_embed_q1[idx] += word2vec[word]\n",
        "            x_embed_q1[idx] /= len(question1)\n",
        "\n",
        "          for word in question2:\n",
        "            if word in word2vec:\n",
        "              x_embed_q2[idx] += word2vec[word]\n",
        "            x_embed_q2[idx] /= len(question2)\n",
        "        \n",
        "\n",
        "        x_embed = np.concatenate((x_embed_q1,x_embed_q2),axis=1)\n",
        "        print(x_embed.shape)\n",
        "\n",
        "        self.feature_size = x_embed.shape[1]\n",
        "        self.x_train = torch.Tensor(x_embed)[:100000]\n",
        "        self.y_train = torch.Tensor(a)[:100000]\n",
        "        print(self.feature_size, self.x_train.shape, self.y_train.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x_train.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x_train[idx], self.y_train[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5VqDBOcWSNev"
      },
      "outputs": [],
      "source": [
        "class LogisticModel(nn.Module):\n",
        "    def __init__(self,input_size):\n",
        "        super(LogisticModel,self).__init__()\n",
        "        self.w = nn.Linear(input_size,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.sigmoid(self.w(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPiSkOTNY0rh",
        "outputId": "c9d8e0fa-59bd-4747-a5bb-2f44d7a7baf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How can I develop android app? nan\n",
            "How can I create an Android app? nan\n",
            "nan My Chinese name is Haichao Yu. What English name is most suitable for me considering the pronounciation of my Chinese name?\n",
            "(404287, 100)\n",
            "100 torch.Size([100000, 100]) torch.Size([100000])\n"
          ]
        }
      ],
      "source": [
        "dataset = Glove50Dataset(X_train,y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ruINwqrgU00"
      },
      "outputs": [],
      "source": [
        "#For Testing\n",
        "model = LogisticModel(dataset.feature_size) \n",
        "\n",
        "params = {  \"loss\": nn.BCELoss(),\n",
        "            \"optimizer\":torch.optim.Adam(model.parameters(), lr=1e-2,betas=(0.9, 0.999)),\n",
        "            \"epochs\": 500 }\n",
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "kfold.split(dataset)\n",
        "train_loss_history, val_loss_history = [], []\n",
        "val_acc_history = []\n",
        "for fold, (train_idxs, test_idxs) in enumerate(kfold.split(dataset)):\n",
        "\n",
        "    print(f'Starting fold {fold}')\n",
        "    train_dataset = torch.utils.data.Subset(dataset,train_idxs)\n",
        "    test_dataset = torch.utils.data.Subset(dataset,test_idxs)\n",
        "    \n",
        "    fold_train_loss_history, fold_val_loss_history, \\\n",
        "    fold_val_acc_history, epoch_history, _ = train(\\\n",
        "                            train_dataset=train_dataset,\n",
        "                            test_dataset=test_dataset,\n",
        "                            feature_size=dataset.feature_size,\n",
        "                            model=model,\n",
        "                            params = params)\n",
        "\n",
        "    train_loss_history.append(fold_train_loss_history)\n",
        "    val_loss_history.append(fold_val_loss_history)\n",
        "    val_acc_history.append(fold_val_acc_history) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITY2hjQKTDM4"
      },
      "source": [
        "# Sentence Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Evn_hzLWDRoh"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_EjEhMElDiDf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaytea/Code_Workspace/Labs/Coen346/NLP-quora-duplicate-detection/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9rbCmavDOAp",
        "outputId": "2eac146f-cb76-440d-8d7d-a8c20371d93c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "class SentenceTransformerDataset():\n",
        "    def __init__(self,X,y, pair_len=0)-> None:\n",
        "        \n",
        "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        \n",
        "        q1 = []\n",
        "        q2 = []\n",
        "        a = []\n",
        "        for (x1, x2),y1 in zip(X,y):\n",
        "          if isinstance(x1, str) and isinstance(x2, str):\n",
        "            q1.append(x1)\n",
        "            q2.append(x2)\n",
        "            a.append(y1)\n",
        "          else:\n",
        "            print(x1,x2)\n",
        "\n",
        "        pair_len = pair_len if pair_len else len(q1)\n",
        "\n",
        "        q1, q2, a = q1[:pair_len], q2[:pair_len], a[:pair_len]\n",
        "        x_embed_q1 = np.zeros((pair_len, 384))[:pair_len]\n",
        "        x_embed_q2 = np.zeros((pair_len, 384)) [:pair_len]\n",
        "\n",
        "        pool = model.start_multi_process_pool()\n",
        "\n",
        "\n",
        "        #Start the multi-process pool on all available CUDA devices\n",
        "        pool = model.start_multi_process_pool()\n",
        "\n",
        "        step_size = 10000\n",
        "        for start in tqdm(range(0, pair_len, step_size),total=pair_len//step_size):\n",
        "          stop = start + step_size if (start + step_size) < pair_len else (pair_len - 1)\n",
        "          x_embed_q1[start:stop] = model.encode_multi_process(q1[start:stop], pool)\n",
        "          x_embed_q2[start:stop] = model.encode_multi_process(q2[start:stop], pool)\n",
        "\n",
        "        #Optional: Stop the proccesses in the pool\n",
        "        model.stop_multi_process_pool(pool)\n",
        "\n",
        "        x_embed = np.concatenate((x_embed_q1,x_embed_q2),axis=1)\n",
        "        \n",
        "        print(x_embed.shape)\n",
        "\n",
        "        self.feature_size = x_embed.shape[1]\n",
        "        self.setences = [q1,q2]\n",
        "        self.x_train = torch.Tensor(x_embed)\n",
        "        self.y_train = torch.Tensor(a)\n",
        "        print(self.feature_size, self.x_train.shape, self.y_train.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x_train.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x_train[idx], self.y_train[idx]\n",
        "\n",
        "\n",
        "\n",
        "print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Kqx5xWXThD",
        "outputId": "4c8697e0-8165-4e7b-b37c-921f92824178"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading (…)e9125/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 17.5MB/s]\n",
            "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 1.68MB/s]\n",
            "Downloading (…)7e55de9125/README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 42.6MB/s]\n",
            "Downloading (…)55de9125/config.json: 100%|██████████| 612/612 [00:00<00:00, 6.11MB/s]\n",
            "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 1.59MB/s]\n",
            "Downloading (…)125/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 623kB/s]\n",
            "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:06<00:00, 14.8MB/s]\n",
            "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 756kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 1.18MB/s]\n",
            "Downloading (…)e9125/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 2.43MB/s]\n",
            "Downloading (…)okenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 3.95MB/s]\n",
            "Downloading (…)9125/train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 57.2MB/s]\n",
            "Downloading (…)7e55de9125/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 3.57MB/s]\n",
            "Downloading (…)5de9125/modules.json: 100%|██████████| 349/349 [00:00<00:00, 3.93MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How can I develop android app? nan\n",
            "How can I create an Android app? nan\n",
            "nan My Chinese name is Haichao Yu. What English name is most suitable for me considering the pronounciation of my Chinese name?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "41it [01:34,  2.31s/it]                        \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(404287, 768)\n",
            "768 torch.Size([404287, 768]) torch.Size([404287])\n",
            "Writing Dataset to Drive\n",
            "Dataset Written!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "create_bert_encoding = True\n",
        "file_name = 'bert_encoding_max.pkl'\n",
        "\n",
        "\n",
        "run = 'y'\n",
        "if create_bert_encoding: \n",
        "  if os.path.isfile(path+file_name):\n",
        "    run = input(f\"'{file_name}' exists in the drive! Would you like to replace? (y/n)\")\n",
        "  if run == 'y':\n",
        "    bert_dataset = SentenceTransformerDataset(X_train,y,pair_len=0)\n",
        "    # Save the object to a file\n",
        "    print(f'Writing Dataset to Drive')\n",
        "    with open(path+file_name, 'wb') as f:\n",
        "        pickle.dump(bert_dataset, f)\n",
        "    print(f'Dataset Written!')\n",
        "\n",
        "if not create_bert_encoding or run != 'y':\n",
        "  # Load the object from the file\n",
        "  if not os.path.isfile(path+file_name):\n",
        "    raise ValueError(\"No Dataset in drive\")\n",
        "  else:\n",
        "    print(f'Loading Dataset from Drive')\n",
        "    with open(path+file_name, 'rb') as f:\n",
        "        bert_dataset = pickle.load(f)\n",
        "    print(f'Dataset Load!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6unhCuBzzih3",
        "outputId": "84e0b1ff-ebce-4587-abf2-63a2a0226e10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train|Val Percent: 0.8|0.19999999999999996\n",
            "Train|Val Size: 323429|80858\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import random_split\n",
        "train_percent = .8\n",
        "val_percent = 1 - train_percent\n",
        "sample_size = len(bert_dataset)\n",
        "train_size = int(sample_size * train_percent)\n",
        "val_size = sample_size - train_size\n",
        "\n",
        "\n",
        "print(f'Train|Val Percent: {train_percent}|{val_percent}')\n",
        "print(f'Train|Val Size: {train_size}|{val_size}')\n",
        "# Split the data into train and test sets\n",
        "train_dataset, test_dataset = random_split(bert_dataset, [train_size, val_size])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "a3dda4d00b524a16b8ddfabea43f3c07",
            "a119a8e7f5574e1e85965abd5749b91b",
            "2d79d95f737b4c34905e0a7f40f91220",
            "69d4cb37419f4a448140d7d1498a2fd5",
            "e194987ed32a4bd6b0b6d18ef0cf1da3",
            "64b3ef56796747fb8d9ef8cf8b4e0171",
            "5021a6b89ed945bf94483e1f9473db3f",
            "f1c5786153924fce9a3a52aac1c1570d",
            "4b2c4fc257474af282c8ba74bc140757",
            "3d79872fbecd4fc6a59cf9b3a01d3581",
            "a99922cd7d32404fb1c746b6fe575056"
          ]
        },
        "id": "5UW1ea5nkIe3",
        "outputId": "b6d29dd5-62a5-4323-dc0f-5a1aca302035"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 80858/80858 [00:03<00:00, 24943.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine Sim Acc: 0.5925325879937668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import util\n",
        "\n",
        "feature_size = bert_dataset.feature_size//2\n",
        "total = 0\n",
        "for x, y in tqdm(test_dataset, total=len(test_dataset)):\n",
        "  q1 = x[:feature_size]\n",
        "  q2 = x[feature_size:]\n",
        "  cosine_scores = util.cos_sim(q1, q2).item()\n",
        "  total += 1 if (cosine_scores >= 0.5)==y else 0 \n",
        "\n",
        "\n",
        "percent = total / len(test_dataset)\n",
        "print(f\"Cosine Sim Acc: {percent}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJBS83PJeFmG",
        "outputId": "5c673554-6cdb-4b40-fb43-7973673eb955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1, Train loss: 0.572877,  Train Acc: 0.708557, Val Loss: 0.567088, Val Acc: 0.710406\n",
            "epoch: 2, Train loss: 0.566894,  Train Acc: 0.712367, Val Loss: 0.566195, Val Acc: 0.711766\n",
            "epoch: 4, Train loss: 0.566116,  Train Acc: 0.712623, Val Loss: 0.565787, Val Acc: 0.712780\n",
            "epoch: 6, Train loss: 0.565991,  Train Acc: 0.712787, Val Loss: 0.565696, Val Acc: 0.712892\n",
            "epoch: 8, Train loss: 0.565958,  Train Acc: 0.712883, Val Loss: 0.565665, Val Acc: 0.712867\n",
            "epoch: 10, Train loss: 0.565947,  Train Acc: 0.712997, Val Loss: 0.565652, Val Acc: 0.712991\n"
          ]
        }
      ],
      "source": [
        "#For Testing\n",
        "\n",
        "model = LogisticModel(bert_dataset.feature_size) \n",
        "\n",
        "params = {  \"loss\": nn.BCELoss(),\n",
        "            \"optimizer\":torch.optim.Adam(model.parameters(), lr=1e-2,betas=(0.9, 0.999)),\n",
        "            \"epochs\": 10 }\n",
        "\n",
        "\n",
        "fold_train_loss_history, fold_val_loss_history, \\\n",
        "    fold_val_acc_history, epoch_history, _ = train(\\\n",
        "                            train_dataset=train_dataset,\n",
        "                            test_dataset=test_dataset,\n",
        "                            feature_size=bert_dataset.feature_size,\n",
        "                            model=model,\n",
        "                            params = params,\n",
        "                            print_step=2)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PdugqPIi9iGm"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d79d95f737b4c34905e0a7f40f91220": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1c5786153924fce9a3a52aac1c1570d",
            "max": 80858,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b2c4fc257474af282c8ba74bc140757",
            "value": 80858
          }
        },
        "3d79872fbecd4fc6a59cf9b3a01d3581": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b2c4fc257474af282c8ba74bc140757": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5021a6b89ed945bf94483e1f9473db3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64b3ef56796747fb8d9ef8cf8b4e0171": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69d4cb37419f4a448140d7d1498a2fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d79872fbecd4fc6a59cf9b3a01d3581",
            "placeholder": "​",
            "style": "IPY_MODEL_a99922cd7d32404fb1c746b6fe575056",
            "value": " 80858/80858 [00:10&lt;00:00, 6166.60it/s]"
          }
        },
        "a119a8e7f5574e1e85965abd5749b91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64b3ef56796747fb8d9ef8cf8b4e0171",
            "placeholder": "​",
            "style": "IPY_MODEL_5021a6b89ed945bf94483e1f9473db3f",
            "value": "100%"
          }
        },
        "a3dda4d00b524a16b8ddfabea43f3c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a119a8e7f5574e1e85965abd5749b91b",
              "IPY_MODEL_2d79d95f737b4c34905e0a7f40f91220",
              "IPY_MODEL_69d4cb37419f4a448140d7d1498a2fd5"
            ],
            "layout": "IPY_MODEL_e194987ed32a4bd6b0b6d18ef0cf1da3"
          }
        },
        "a99922cd7d32404fb1c746b6fe575056": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e194987ed32a4bd6b0b6d18ef0cf1da3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1c5786153924fce9a3a52aac1c1570d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
